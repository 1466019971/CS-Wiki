# 🔮 十、应用机器学习的建议 Advice for Applying Machine Learning

## 1. 本节内容

假如你在开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，你应如何决定接下来应该选择哪条道路？

为了解释这一问题，我们仍然使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数的值，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？ 

实际上你可以想出很多种方法来改进这个算法的性能：

- 获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。

- 尝试减少特征的数量

- 尝试获得更多的特征

- 尝试增加多项式特征

- 尝试减少正则化程度

- 尝试增加正则化程度

其中一种办法是使用更多的训练样本。具体来讲，也许你能想到通过电话调查或上门调查来获取更多的不同的房屋出售数据。遗憾的是，我看到好多人花费了好多时间想收集更多的训练样本。他们总认为，要是我有两倍甚至十倍数量的训练数据，那就一定会解决问题的是吧？但有时候获得更多的训练数据实际上并没有作用。在接下来的几段视频中，我们将解释原因。 我们也将知道**怎样避免把过多的时间浪费在收集更多的训练数据上**，这实际上是于事无补的。

另一个方法，你也许能想到的是尝试选用更少的特征集。因此如果你有一系列特征比如 x1, x2, x3 等等。也许有很多特征，也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合。或者也许你需要用更多的特征，也许目前的特征集，对你来讲并不是很有帮助。你希望从获取更多特征的角度来收集更多的数据，同样地，你可以把这个问题扩展为一个很大的项目，比如使用电话调查来得到更多的房屋案例，或者再进行土地测量来获得更多有关，这块土地的信息等等，因此这是一个复杂的问题。同样的道理，👀 **我们非常希望在花费大量时间完成这些工作之前，我们就能知道其效果如何**。

我们也可以尝试增加多项式特征的方法，比如 x1 的平方，x2 的平方，x1 x2 的乘积，我们可以花很多时间来考虑这一方法，我们也可以考虑其他方法减小或增大正则化参数的值。我们列出的这个单子，上面的很多方法都可以扩展开来扩展成一个六个月或更长时间的项目。遗憾的是，大多数人用来选择这些方法的标准是凭感觉的，😮 **也就是说，大多数人的选择方法是随便从这些方法中选择一种**，比如他们会说“噢，我们来多找点数据吧”，然后花上六个月的时间收集了一大堆数据，然后也许另一个人说：“好吧，让我们来从这些房子的数据中多找点特征吧”。我很遗憾不止一次地看到很多人花了至少六个月时间来完成他们随便选择的一种方法，而在六个月或者更长时间后，他们很遗憾地发现自己选择的是一条不归路。

幸运的是，有一系列简单的方法能让你事半功倍，排除掉单子上的至少一半的方法，留下那些确实有前途的方法，同时也有一种很简单的方法，只要你使用，就能很轻松地排除掉很多选择，从而为你节省大量不必要花费的时间。

⭐ **我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的**。

在接下来的两段视频中，我首先介绍怎样评估机器学习算法的性能，然后在之后的几段视频中，我将开始讨论这些方法，它们也被称为"**机器学习诊断法**"。🔴 “诊断法”的意思是：**这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用**。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。

在这一系列的视频中我们将介绍具体的诊断法，但我要提前说明一点的是，这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上，因为这些方法让你在开发学习算法时，节省了几个月的时间，

## 2. 评估假设函数  Evaluating a Hypothesis

在本节中我想介绍一下**怎样用你学过的算法来评估假设函数**。在之后的课程中，我们将以此为基础来讨论如何避免过拟合和欠拟合的问题。

当我们确定学习算法的参数的时候，我们考虑的是选择参量来使**训练误差**最小化，有人认为得到一个非常小的训练误差一定是一件好事，但我们已经知道，很小的训练误差也可能是过拟合的假设函数，所以这推广到新的训练集上是不适用的。

❓ 那么，该**如何判断一个假设函数是过拟合的呢**？

⭐ 我们将数据分成训练集和测试集，通常用 **70% 的数据作为训练集，用剩下 30% 的数据作为测试集**。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“**洗牌**”，然后再分成训练集和测试集。

<img src="https://gitee.com/veal98/images/raw/master/img/20200608220453.png" style="zoom:50%;" />

测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：

- 对于**线性回归**模型，我们利用测试集数据计算代价函数 J

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608220948.png" style="zoom:50%;" />

- 对于**逻辑回归**模型，我们同样利用测试数据集来计算代价函数：

  ![](https://gitee.com/veal98/images/raw/master/img/20200608221219.png)

  对于每一个测试集样本，计算误分类的比率：

  ![](https://gitee.com/veal98/images/raw/master/img/20200608221337.png)

  然后对计算结果求平均。

## 3. 模型选择和训练、验证、测试集 Model Selection and Train_Validation_Test Sets

假设你想要确定对于一个数据集最合适的多项式次数，怎样选用正确的特征来构造学习算法，或者你应该如何选择学习算法中的正则化参数 lmabda呢？这类问题被叫做**模型选择问题 model selection problems**。在这类问题中，我们不仅仅是把数据集分为训练集和测试集，而是将其分为训练集、验证集和测试集。 

💬 假设我们要在10个不同次数的二项式模型之间进行选择：

![](https://gitee.com/veal98/images/raw/master/img/20200608222445.png)

显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。 ⭐ 即：**使用60%的数据作为训练集 Train，使用 20%的数据作为交叉验证集 Cross Validaton，使用20%的数据作为测试集 Test**

<img src="https://gitee.com/veal98/images/raw/master/img/20200608222601.png" style="zoom:50%;" />

模型选择的方法为：

- 使用训练集训练出10个模型

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608223059.png" style="zoom:50%;" />

- 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608223114.png" style="zoom:50%;" />![](https://gitee.com/veal98/images/raw/master/img/20200608223127.png)

- 选取代价函数值最小的模型

- 用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）

  ![](https://gitee.com/veal98/images/raw/master/img/20200608223127.png)



⭐总结：**训练集求出模型的参数，验证集带入模型选出损失函数最小的模型，最后用测试集评估该模型泛化能力**

## 4. 诊断偏差和方差 Diagnosing Bias and Variance

当你运行一个学习算法时，**如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大**。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？搞清楚这一点非常重要，因为能判断出现的情况是这两种情况中的哪一种。其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。

我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：

<img src="https://gitee.com/veal98/images/raw/master/img/20200608224131.png" style="zoom:50%;" />

对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着 d 的增长，拟合程度提高，误差减小。 对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d  的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。 如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？

🚩 **离原点较近的便是高偏差问题 Bias，离原点较远的就是高方差问题 Variance**。从图中可以看出：

- **高偏差**：

  $J_{train}(θ)$ 训练误差 很大 （表示假设函数不能很好的拟合训练集）

  $J_{cv}(θ)$ 交叉验证误差 ≈ $J_{train}(θ)$

- **高方差**：

  $J_{train}(θ)$ 训练误差 很小 （表示假设函数很好的拟合了训练集）

  $J_{cv}(θ)$ 交叉验证误差 远远大于 $J_{train}(θ)$

## 5. 正则化和偏差/方差 Regularization and Bias_Variance

在我们在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是我们可能会正则化的程度太高或太小了，即我们在选择 λ 的值时也需要思考与刚才选择多项式模型次数类似的问题。

![](https://gitee.com/veal98/images/raw/master/img/20200609143947.png)

我们选择一系列的想要测试的 λ 值，通常是 0-10 之间的呈现 2 倍关系的值：

<img src="https://gitee.com/veal98/images/raw/master/img/20200609144047.png" style="zoom:50%;" />

选择  λ  的方法为：

- 使用训练集训练出12个不同程度正则化的模型

- 用12个模型分别对交叉验证集计算得出交叉验证误差

- ⭐ **选择得出交叉验证误差最小的模型**

- 运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：

  <img src="https://gitee.com/veal98/images/raw/master/img/20200609144628.png" style="zoom:50%;" />

🚩 当  λ   较小时，训练集误差较小（过拟合）而交叉验证集误差较大；随着   λ  的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加

## 6. 学习曲线  Learning Curves

学习曲线就是一种很好的工具，我经常**使用学习曲线来判断某一个学习算法是否处于偏差、方差问题**。学习曲线是学习算法的一个很好的**合理检验**（**sanity check**）。

🔴 **学习曲线是将训练集误差和交叉验证集误差作为训练集样本数量（m）的函数绘制的图表**。 即，如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。

当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。

<img src="https://gitee.com/veal98/images/raw/master/img/20200609145520.png" style="zoom:50%;" />

❓ **如何利用学习曲线识别高偏差/欠拟合呢？**作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：

<img src="https://gitee.com/veal98/images/raw/master/img/20200609150455.png" style="zoom:50%;" />

⭐ 也就是说**在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助**

❓ **如何利用学习曲线识别高方差/过拟合？**假设我们使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果：

<img src="https://gitee.com/veal98/images/raw/master/img/20200609150759.png" style="zoom:50%;" />

⭐ 也就是说**在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果**。

## 7. 小结

我们已经介绍了怎样评价一个学习算法，我们讨论了模型选择问题，偏差和方差的问题。那么这些诊断法则怎样帮助我们判断，哪些方法可能有助于改进学习算法的效果，而哪些可能是徒劳的呢？回顾第 1 节 中提出的六种可选的方法，让我们来看一看我们在什么情况下应该怎样选择：⭐ 

- 获得更多的训练样本 —— 解决高方差

- 尝试减少特征的数量 —— 解决高方差

- 尝试获得更多的特征 —— 解决高偏差

- 尝试增加多项式特征 —— 解决高偏差

- 尝试减少正则化程度 λ —— 解决高偏差

- 尝试增加正则化程度 λ —— 解决高方差

👇 **神经网络的方差和偏差**：

![](https://gitee.com/veal98/images/raw/master/img/20200609151613.png)

使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。 

🚩 **通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。** 

🚩 **对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数**，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，**针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。**

## ✍ Quiz

### ① 第 1 题

你训练一个学习算法，发现它<u>在测试集上的误差很高</u>。绘制学习曲线，并获得下图。算法是否存在高偏差、高方差或两者都不存在？

![](https://gitee.com/veal98/images/raw/master/img/20200611170212.png)

- ✅ 高偏差 
- 高方差
- 两者都不

> 💡 （训练集误差 ≈ 测试集误差 且 训练集/测试集 误差较高）

### ② 第 2 题

假设您已经实现了正则化逻辑回归来分类图像中的对象（即，还没有实现图像识别）。然而，当你在一组新的图像上检验你的模型时，你会发现它<u>对新图像的预测有误差非常大</u>。然而，你的假设<u>在训练集上拟合的很好</u>。以下哪个做法可以改善？选出所有正确项

- 尝试添加多项式特征 
- ✅ 获取更多训练示例 
- ✅ 尝试使用较少的特征 
- 少用训练的例子

> 💡 此题是高方差问题
>
> - 获得更多的训练样本 —— 解决高方差
>
> - 尝试减少特征的数量 —— 解决高方差
>
> - 尝试获得更多的特征 —— 解决高偏差
>
> - 尝试增加多项式特征 —— 解决高偏差
>
> - 尝试减少正则化程度 λ —— 解决高偏差
>
> - 尝试增加正则化程度 λ —— 解决高方差

### ③ 第 3 题

假设您已经实现了正则化的逻辑来预测客户将在购物网站上购买哪些商品。然而，当你在一组新的客户身上测试你的模型时，你发现它在预测中的误差很大。此外，该模型<u>在训练集上表现不佳</u>。以下哪个做法可以改善？选出所有正确项

- ✅ 尝试获取并使用其他特征 
- ✅ 尝试添加多项式特征 
- 尝试使用较少的特征 
- 尝试增加正则化参数 λ

> 💡 此题是高偏差问题

### ④ 第 4 题

以下哪项陈述是正确的？选出所有正确项

- ✅ 假设您正在训练一个正则化的线性回归模型。选择正则化参数 λ 值的推荐方法是选择交叉验证误差最小的 λ 值。

- 假设您正在训练一个正则化的线性回归模型。选择正则化参数 λ 值的推荐方法是选择给出最小测试集误差的 λ 值。

- 假设你正在训练一个正则化线性回归模型，推荐的选择正则化参数 λ 值的方法是选择给出最小训练集误差的 λ 值。

- ✅ 学习算法在训练集上的性能通常比在测试集上的性能要好。

### ⑤ 第 5 题

以下哪项陈述是正确的？选出所有正确项

- ✅ 在调试学习算法时，绘制学习曲线有助于了解是否存在高偏差或高方差问题。

- ✅ 如果一个学习算法受到高方差的影响，增加更多的训练实例可能会改善测试误差。

- 我们总是喜欢高方差的模型（而不是高偏差的模型），因为它们能够更好地适应训练集。

- ✅ 如果一个学习算法有很高的偏差，仅仅增加更多的训练实例可能不会显著改善测试误差。

---



# 🎸 十一、机器学习系统的设计 Machine Learning System Design

## 1. 首先要做什么 Prioritizing What to Work On

在接下来的视频中，我将谈到机器学习系统的设计。这些视频将谈及在设计复杂的机器学习系统时，你将遇到的主要问题。同时我们会试着给出一些关于如何巧妙构建一个复杂的机器学习系统的建议。下面的课程的的数学性可能不是那么强，但是我认为我们将要讲到的这些东西是非常有用的，可能在构建大型的机器学习系统时，节省大量的时间。 

<u>💬 以一个垃圾邮件分类器算法为例进行讨论：</u>

为了解决这样一个问题，⭐ **我们首先要做的决定是如何选择并表达特征向量 x** 。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。

为了构建这个分类器算法，我们可以做很多事，例如：

- 收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本

- 基于邮件的路由信息开发一系列复杂的特征

- 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理

- 为探测刻意的拼写错误（把**watch** 写成**w4tch**）开发复杂的算法

在上面这些选项中，非常难决定应该在哪一项上花费时间和精力。我们将在随后的课程中讲**误差分析**，我会告诉你怎样用一个更加系统性的方法，从一堆不同的方法中，选取合适的那一个。

## 2. 误差分析 Error Analysis

如果你准备研究机器学习的东西，或者构造机器学习应用程序，**最好的实践方法不是建立一个非常复杂的系统，拥有多么复杂的变量，而是构建一个简单的算法，这样你可以很快地实现它**。 坦白的说，就是根本没有用复杂的系统，但是很快的得到结果。即便运行得不完美，但是也把它运行一遍，最后通过交叉验证来检验数据。一旦做完，你可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出你的算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。

这么做的原因是：你并不能提前知道你是否需要复杂的特征变量，或者你是否需要更多的数据，还是别的什么，因为你缺少证据，缺少学习曲线。因此，你很难知道你应该把时间花在什么地方来提高算法的表现。但是当你实践一个非常简单即便不完美的方法时，你可以通过画出学习曲线来做出进一步的选择。

你可以用这种方式来避免一种电脑编程里的过早优化问题，这种理念是：**我们必须用证据来领导我们的决策**，怎样分配自己的时间来优化算法，而不是仅仅凭直觉，凭直觉得出的东西一般总是错误的。

除了画出学习曲线之外，一件非常有用的事是误差分析，我的意思是说：当我们在构造垃圾邮件分类器时，我会看一看我的交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，你可以发现某些系统性的规律：什么类型的邮件总是被错误分类。经常地这样做之后，这个过程能启发你构造新的特征变量，或者告诉你：现在这个系统的短处，然后启发你如何去提高它。 

⭐ **构建一个学习算法的推荐方法为**：

- <u>从一个简单的能快速实现的算法开始</u>，实现该算法并用交叉验证集数据测试这个算法

- <u>绘制学习曲线</u>，决定是增加更多数据，或者添加更多特征，还是其他选择 
- <u>进行误差分析</u>：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势

## 3. 类偏斜的误差度量 Error Metrics for Skewed Classes

在前面的课程中，我提到了误差分析，以及设定误差度量值的重要性。那就是，设定某个实数来评估你的学习算法，并衡量它的表现，有了算法的评估和误差度量值。有一件重要的事情要注意，就是使用一个合适的误差度量值，这有时会对于你的学习算法造成非常微妙的影响，这件重要的事情就是**偏斜类（skewed classes）**的问题。

🔴 **类偏斜情况表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本**。 例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤<u>。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，我们并不能说非学习来的算法要比训练来的算法准确。</u>

所以，用某个实数来作为评估度量值，对于偏斜类问题来说可能不是最好的方案，🚩 <u>我们可以使用 **查准率**（**Precision**）和**查全率 / 召回率**（**Recall**） 作为偏斜类问题的评估度量值</u>，将算法预测的结果分成四种情况：

- **正确肯定**（**True Positive,TP**）：预测为真，实际为真
- **正确否定**（**True Negative,TN**）：预测为假，实际为假 
- **错误肯定**（**False Positive,FP**）：预测为真，实际为假 
- **错误否定**（**False Negative,FN**）：预测为假，实际为真

<img src="https://gitee.com/veal98/images/raw/master/img/20200609155848.png"  />

**查准率 = TP/(TP+FP)**：即我们预测这些病人的肿瘤是恶性的，对于这些病人来说，有多大概率是真正患有癌症的？这就是查准率。高查准率表示我们预测这些病人的肿瘤是恶性的，这个预测具有很高的准确性。

**查全率 = TP/(TP+FN)**：即如果数据集中的所有人的肿瘤都是恶性的，有多少人我们能够正确告诉他们，你需要治疗。显然，查全率越高越好

## 4. 查准率和查全率之间的权衡 Trading Off Precision and Recall

在之前的课程中，我们谈到查准率和查全率，作为遇到偏斜类问题的评估度量值。**在很多应用中，我们希望能够保证查准率和查全率的相对平衡。** 在这节课中，我将告诉你应该怎么做，同时也向你展示一些查准率和召回率作为算法评估度量值的更有效的方式。

继续沿用刚才预测肿瘤性质的例子。假使，我们的算法输出的结果在0-1 之间，我们使用 阀值（threshold）0.5 来预测真和假：

![](https://gitee.com/veal98/images/raw/master/img/20200609160101.png)

🚩 如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望**更高的查准率**，我们**可以使用比 0.5 更大的阀值**，如 0.7，0.9。**这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。** 

🚩 如果我们希望**提高查全率**，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以**使用比0.5更小的阀值**，如0.3。

我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：

![](https://gitee.com/veal98/images/raw/master/img/20200609160232.png)

我们希望有一个帮助我们选择这个阀值的方法。一种方法是计算**F1 值**（**F1 Score**），其计算公式为：

<img src="https://gitee.com/veal98/images/raw/master/img/20200609160419.png" style="zoom: 33%;" />

<u>P 就是 Precision 查准率，R 就是 Recall 查全率</u>

**我们选择使得F1值最高的阀值**。

## 5. 机器学习的数据 Data For Machine Learning

⭐ **一个好的机器学习并不是又有最好的算法，而是拥有最大的数据**



## ✍ Quiz

### ① 第 1 题

你正在研究一个垃圾邮件分类系统，准备使用正则化的逻辑回归。“垃圾邮件”是正类（y=1），“非垃圾邮件”是负类（y=0）。您已经训练了分类器，交叉验证集中有m=1000个示例。预测类与实际类的图表为：

|                    | Actual Class：1 | Actual Class：0 |
| :----------------: | :-------------: | :-------------: |
| Predicted Class：1 |       85        |       890       |
| Predicted Class：0 |       15        |       10        |

分类器的召回率 Recall 是多少？

> 💡 Recall = 85 / 85 + 15 = 0.85
>
> ![](https://gitee.com/veal98/images/raw/master/img/20200611172604.png)

### ② 第 2 题

假设一个庞大的数据集可以用来训练一个学习算法。当以下两个条件成立时，对大量数据进行训练可能会产生良好的性能。两个条件是哪两个？

- ✅ 特征x包含足够的信息来精确地预测y。（例如，一个验证这一点的方法是，当只给x时，人类专家是否能够自信地预测y）。

- 我们训练一个具有少量参数的学习算法（因此不太可能过拟合）。

- ✅ 我们训练具有大量参数的学习算法（能够学习/表示相当复杂的函数）。

- 我们训练一个不使用正则化的模型。

### ③ 第 3 题

假设您已经训练了一个输出hθ(x)的逻辑回归分类器。 目前，如果hθ(x)≥threshold，则预测1， 如果hθ(x)≤threshold，则预测0，当前阈值设置为0.5。

假设您将阈值增加到0.9。以下哪项是正确的？选出所有正确项

- 现在分类器的精度可能更低。

- 分类器的准确度和召回率可能不变，但准确度较低。

- 分类器的准确度和召回率可能不变，但精度较高。

- ✅ 分类器现在可能具有较低的召回率。

假设您将阈值降低到0.3。以下哪项是正确的？选出所有正确项

- ✅ 分类器现在可能具有更高的召回率。

- 分类器的准确度和召回率可能不变，但精度较高。

- 分类器现在可能具有更高的精度。

- 分类器的准确度和召回率可能不变，但准确度较低。

> 💡 ![](https://gitee.com/veal98/images/raw/master/img/20200609160232.png)

### ④ 第 4 题

假设您正在使用垃圾邮件分类器，其中垃圾邮件是正例（y=1），非垃圾邮件是反例（y=0）。<u>您有一组电子邮件训练集，其中99%的电子邮件是非垃圾邮件，另1%是垃圾邮件</u>。以下哪项陈述是正确的？选出所有正确项

- 一个好的分类器应该在交叉验证集上同时具有高精度precision和高召回率recall。

- ✅ 如果您总是预测非垃圾邮件（输出y=0），那么您的分类器在训练集上的准确度accuracy将达到99%，而且它在交叉验证集上的性能可能类似。

- ✅ 如果您总是预测非垃圾邮件（输出y=0），那么您的分类器的准确度accuracy将达到99%。

- ✅ 如果您总是预测非垃圾邮件（输出y=0），那么您的分类器在训练集上的准确度accuracy将达到99%，但在交叉验证集上的准确率会更差，因为它过拟合训练数据。

- 如果总是预测垃圾邮件（输出y=1），则分类器的召回率recall为0%，精度precision为99%。

- ✅ 如果总是预测非垃圾邮件（输出y=0），则分类器的召回率recall为0%。

- ✅ 如果您总是预测垃圾邮件（输出y=1），那么您的分类器将具有召回率recall 100%和精度precision 1%。

- ✅ 如果您总是预测非垃圾邮件（输出y=0），那么您的分类器的准确度accuracy将达到99%。

### ⑤ 第 5 题

以下哪项陈述是正确的？选出所有正确项

- 在构建学习算法的第一个版本之前，花大量时间收集大量数据是一个好主意。

- ✅ 在倾斜的数据集上（例如，当有更多的正面例子而不是负面例子时），准确度不是一个很好的性能度量，您应该根据准确度和召回率使用F1分数。

- 训练完逻辑回归分类器后，必须使用0.5作为预测示例是正是负的阈值。

- ✅ 使用一个非常大的训练集使得模型不太可能过度拟合训练数据。

- 如果您的模型不适合训练集，那么获取更多数据可能会有帮助。

---

# 📚 References

- 🤖 [吴恩达机器学习经典名课【中英字幕】](https://www.bilibili.com/video/BV164411S78V?p=2)

- 💠 [黄海广 - 斯坦福大学2014机器学习教程中文笔记](http://www.ai-start.com/ml2014/)

- 🍧 [90题细品吴恩达《机器学习》，感受被刷题支配的恐惧](https://www.kesci.com/home/project/5e0f01282823a10036b280a7)