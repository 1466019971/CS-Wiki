# 🔮 十、应用机器学习的建议 Advice for Applying Machine Learning

## 1. 本节内容

假如你在开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，你应如何决定接下来应该选择哪条道路？

为了解释这一问题，我们仍然使用预测房价的学习例子，假如你已经完成了正则化线性回归，也就是最小化代价函数的值，在你得到你的学习参数以后，如果你要将你的假设函数放到一组新的房屋样本上进行测试，假如说你发现在预测房价时产生了巨大的误差，现在你的问题是要想改进这个算法，接下来应该怎么办？ 

实际上你可以想出很多种方法来改进这个算法的性能：

- 获得更多的训练样本——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。

- 尝试减少特征的数量

- 尝试获得更多的特征

- 尝试增加多项式特征

- 尝试减少正则化程度

- 尝试增加正则化程度

其中一种办法是使用更多的训练样本。具体来讲，也许你能想到通过电话调查或上门调查来获取更多的不同的房屋出售数据。遗憾的是，我看到好多人花费了好多时间想收集更多的训练样本。他们总认为，要是我有两倍甚至十倍数量的训练数据，那就一定会解决问题的是吧？但有时候获得更多的训练数据实际上并没有作用。在接下来的几段视频中，我们将解释原因。 我们也将知道**怎样避免把过多的时间浪费在收集更多的训练数据上**，这实际上是于事无补的。

另一个方法，你也许能想到的是尝试选用更少的特征集。因此如果你有一系列特征比如 x1, x2, x3 等等。也许有很多特征，也许你可以花一点时间从这些特征中仔细挑选一小部分来防止过拟合。或者也许你需要用更多的特征，也许目前的特征集，对你来讲并不是很有帮助。你希望从获取更多特征的角度来收集更多的数据，同样地，你可以把这个问题扩展为一个很大的项目，比如使用电话调查来得到更多的房屋案例，或者再进行土地测量来获得更多有关，这块土地的信息等等，因此这是一个复杂的问题。同样的道理，👀 **我们非常希望在花费大量时间完成这些工作之前，我们就能知道其效果如何**。

我们也可以尝试增加多项式特征的方法，比如 x1 的平方，x2 的平方，x1 x2 的乘积，我们可以花很多时间来考虑这一方法，我们也可以考虑其他方法减小或增大正则化参数的值。我们列出的这个单子，上面的很多方法都可以扩展开来扩展成一个六个月或更长时间的项目。遗憾的是，大多数人用来选择这些方法的标准是凭感觉的，😮 **也就是说，大多数人的选择方法是随便从这些方法中选择一种**，比如他们会说“噢，我们来多找点数据吧”，然后花上六个月的时间收集了一大堆数据，然后也许另一个人说：“好吧，让我们来从这些房子的数据中多找点特征吧”。我很遗憾不止一次地看到很多人花了至少六个月时间来完成他们随便选择的一种方法，而在六个月或者更长时间后，他们很遗憾地发现自己选择的是一条不归路。

幸运的是，有一系列简单的方法能让你事半功倍，排除掉单子上的至少一半的方法，留下那些确实有前途的方法，同时也有一种很简单的方法，只要你使用，就能很轻松地排除掉很多选择，从而为你节省大量不必要花费的时间。

⭐ **我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的**。

在接下来的两段视频中，我首先介绍怎样评估机器学习算法的性能，然后在之后的几段视频中，我将开始讨论这些方法，它们也被称为"**机器学习诊断法**"。🔴 “诊断法”的意思是：**这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用**。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。

在这一系列的视频中我们将介绍具体的诊断法，但我要提前说明一点的是，这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上，因为这些方法让你在开发学习算法时，节省了几个月的时间，

## 2. 评估假设函数  Evaluating a Hypothesis

在本节中我想介绍一下**怎样用你学过的算法来评估假设函数**。在之后的课程中，我们将以此为基础来讨论如何避免过拟合和欠拟合的问题。

当我们确定学习算法的参数的时候，我们考虑的是选择参量来使**训练误差**最小化，有人认为得到一个非常小的训练误差一定是一件好事，但我们已经知道，很小的训练误差也可能是过拟合的假设函数，所以这推广到新的训练集上是不适用的。

❓ 那么，该**如何判断一个假设函数是过拟合的呢**？

⭐ 我们将数据分成训练集和测试集，通常用 **70% 的数据作为训练集，用剩下 30% 的数据作为测试集**。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“**洗牌**”，然后再分成训练集和测试集。

<img src="https://gitee.com/veal98/images/raw/master/img/20200608220453.png" style="zoom:50%;" />

测试集评估在通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：

- 对于**线性回归**模型，我们利用测试集数据计算代价函数 J

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608220948.png" style="zoom:50%;" />

- 对于**逻辑回归**模型，我们同样利用测试数据集来计算代价函数：

  ![](https://gitee.com/veal98/images/raw/master/img/20200608221219.png)

  对于每一个测试集样本，计算误分类的比率：

  ![](https://gitee.com/veal98/images/raw/master/img/20200608221337.png)

  然后对计算结果求平均。

## 3. 模型选择和训练、验证、测试集 Model Selection and Train_Validation_Test Sets

假设你想要确定对于一个数据集最合适的多项式次数，怎样选用正确的特征来构造学习算法，或者你应该如何选择学习算法中的正则化参数 lmabda呢？这类问题被叫做**模型选择问题 model selection problems**。在这类问题中，我们不仅仅是把数据集分为训练集和测试集，而是将其分为训练集、验证集和测试集。 

💬 假设我们要在10个不同次数的二项式模型之间进行选择：

![](https://gitee.com/veal98/images/raw/master/img/20200608222445.png)

显然越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。 ⭐ 即：**使用60%的数据作为训练集 Train，使用 20%的数据作为交叉验证集 Cross Validaton，使用20%的数据作为测试集 Test**

<img src="https://gitee.com/veal98/images/raw/master/img/20200608222601.png" style="zoom:50%;" />

模型选择的方法为：

- 使用训练集训练出10个模型

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608223059.png" style="zoom:50%;" />

- 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）

  <img src="https://gitee.com/veal98/images/raw/master/img/20200608223114.png" style="zoom:50%;" />![](https://gitee.com/veal98/images/raw/master/img/20200608223127.png)

- 选取代价函数值最小的模型

- 用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）

  ![](https://gitee.com/veal98/images/raw/master/img/20200608223127.png)



⭐总结：**训练集求出模型的参数，验证集带入模型选出损失函数最小的模型，最后用测试集评估该模型泛化能力**

## 4. 诊断偏差和方差 Diagnosing Bias and Variance

当你运行一个学习算法时，**如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大**。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？搞清楚这一点非常重要，因为能判断出现的情况是这两种情况中的哪一种。其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。

我们通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：

<img src="https://gitee.com/veal98/images/raw/master/img/20200608224131.png" style="zoom:50%;" />

对于训练集，当 d 较小时，模型拟合程度更低，误差较大；随着 d 的增长，拟合程度提高，误差减小。 对于交叉验证集，当 d 较小时，模型拟合程度低，误差较大；但是随着 d  的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。 如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？

🚩 **离原点较近的便是高偏差问题 Bias，离原点较远的就是高方差问题 Variance**。从图中可以看出：

- **高偏差**：

  $J_{train}(θ)$ 训练误差 很大 （表示假设函数不能很好的拟合训练集）

  $J_{cv}(θ)$ 交叉验证误差 ≈ $J_{train}(θ)$

- **高方差**：

  $J_{train}(θ)$ 训练误差 很小 （表示假设函数很好的拟合了训练集）

  $J_{cv}(θ)$ 交叉验证误差 远远大于 $J_{train}(θ)$

## 5. 正则化和偏差/方差 Regularization and Bias_Variance



## 6. 学习曲线



## 7. 下节内容





---



# 🎸 十一、机器学习系统的设计 Machine Learning System Design

## 1. 首先要做什么

## 2. 误差分析

## 3. 类偏斜的误差度量

## 4. 查准率和查全率之间的权衡

## 5. 机器学习的数据



---

# 📚 References

- 🤖 [吴恩达机器学习经典名课【中英字幕】](https://www.bilibili.com/video/BV164411S78V?p=2)

- 💠 [黄海广 - 斯坦福大学2014机器学习教程中文笔记](http://www.ai-start.com/ml2014/)

- 🍧 [90题细品吴恩达《机器学习》，感受被刷题支配的恐惧](https://www.kesci.com/home/project/5e0f01282823a10036b280a7)