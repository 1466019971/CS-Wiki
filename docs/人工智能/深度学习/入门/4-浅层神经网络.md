# 🥙 浅层神经网络

---



## 2. 神经网络的表示

下面系统的总结一下神经网络的表示以及相关术语：

![](https://gitee.com/veal98/images/raw/master/img/20200920154746.png)

- 我们有 3 个输入特征，它们被竖直地堆叠起来，这叫做神经网络的**输入层**。它包含了神经网络的输入；

- 中间层我们称之为**隐藏层**：在一个神经网络中，当你使用监督学习训练它的时候，训练集包含了输入也包含了目标输出，神经网络的神奇之处就在于**我们不必去关心中间层（隐藏层）的取值**，只需要输入 x，就能得到输出 y。所以人们常说神经网络就像一个**黑盒子**
- 在本例中最后一层只由一个结点构成，而这个只有一个结点的层被称为**输出层**，它负责产生预测值 y。

📐 现在我们再引入几个符号：

- 这里有个可代替的记号 $a^{[0]}$ 可以用来表示输入特征。$a$ 表示激活 active 的意思，它意味着网络中不同层的值会传递到它们后面的层中，一般来说，我们将输入层称为第 0 层，所以将输入层的值称为 $a^{[0]}$；

  > 🚨 注意：在这里你所看到的这个例子，只能叫做一个两层的神经网络。原因是当我们计算网络的层数时，**输入层是不算入总层数内**，所以隐藏层是第一层，输出层是第二层。
  >
  > 我们将输入层称为第零层，所以在技术上，这仍然是一个三层的神经网络，因为这里有输入层、隐藏层，还有输出层。但是在传统的符号使用中，如果你阅读研究论文，你会看到人们将这个神经网络称为一个两层的神经网络。

- **输入层的数据经过激活函数产生激活值进入隐藏层**，将其记作 $a^{[1]}$。所以具体地，这里的第一个单元或结点产生的激活值表示为$a^{[1]}_{1}$，第二个结点的激活值我们记为$a^{[1]}_{2}$。以此类推。

  所以这里的是一个四维的向量，如果写成 Python 代码，那么它是一个规模为4x1的矩阵或一个大小为4的列向量，如下公式，它是四维的，因为在本例中，我们有四个结点或者单元，或者称为四个隐藏层单元：

  <img src="https://gitee.com/veal98/images/raw/master/img/20200920155743.png" style="zoom:80%;" />

- 最后输出层将产生某个数值 $a$，它只是一个单独的实数并处于第 2 层，所以的$\hat{y}$值将取为 $a^{[2]}$。

  > 💡 这与逻辑回归很相似，在逻辑回归中，我们有 $\hat{y}$ 直接等于 $a$，在逻辑回归中我们只有一个输出层，所以我们没有用带方括号的上标。但是在神经网络中，**我们将使用这种带上标的形式来明确地指出这些值来自于哪一层**。

## 3. 计算一个神经网络的输出

> 😶 在上一节，我们介绍只有一个隐藏层的神经网络的结构与符号表示。在本节我们将了解神经网络的输出究竟是如何计算出来的。

## 4. 激活函数